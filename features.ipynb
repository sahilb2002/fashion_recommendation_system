{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute and store features vectors for all images in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "# Load the complete model\n",
    "model_comp = models.load_model('../models/model_v5_0/')\n",
    "print(len(model_comp.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 2048)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seperate the feature extractor (the xception model base)\n",
    "encoder = models.Sequential()\n",
    "encoder.add(models.Model(model_comp.input, model_comp.layers[-2].output))\n",
    "encoder.add(keras.layers.GlobalAveragePooling2D())\n",
    "encoder.trainable = False\n",
    "encoder.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate the classifier\n",
    "classifier = models.Model(model_comp.layers[-1].layers[1].input,model_comp.layers[-1].output)\n",
    "classifier.trainable = False\n",
    "classifier.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_accuracy(y_actual, y_pred):\n",
    "    np.sum(y_actual == y_pred)/len(y_actual)\n",
    "\n",
    "# compute the features of images\n",
    "def get_feature(img_paths):\n",
    "    imgs = []\n",
    "    for img_path in img_paths:\n",
    "        # load ans scale the image\n",
    "        img = keras.preprocessing.image.load_img(img_path, target_size=(224,224))\n",
    "        img = keras.preprocessing.image.img_to_array(img)\n",
    "        img = img.astype('float32')/255.0\n",
    "        imgs.append(img)\n",
    "    \n",
    "    feature = encoder.predict(np.array(imgs), verbose=0)\n",
    "    return list(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_name', 'category_label'], dtype='object')\n",
      "32 (2048,)\n"
     ]
    }
   ],
   "source": [
    "# load the database\n",
    "database = pd.read_csv('../dataset/anno/img_label_database2.csv')\n",
    "database.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "y_pred = []\n",
    "batch = 32\n",
    "n = len(database)\n",
    "\n",
    "# compute the features of all images in the database.\n",
    "for i  in tqdm(range(0,n,batch)):\n",
    "    features = features + get_feature(database['image_name'].iloc[i:min(i+batch,n)])\n",
    "\n",
    "database.insert(2, 'feature', features)\n",
    "\n",
    "# compute the predictions of all images in the database.\n",
    "for i in tqdm(range(0,n,batch)):\n",
    "    y_pred = y_pred + list(np.argmax(classifier.predict(np.array(database['feature'].iloc[i:min(i+batch,n)]), verbose=0),axis=1).flatten())\n",
    "\n",
    "# change the predictions to the labels as per the label map obtained from data generator\n",
    "label_map = [0,1,10,2,3,4,5,6,7,8,9]\n",
    "for i in tqdm(range(n)):\n",
    "  y_pred[i] = label_map[y_pred[i]]\n",
    "\n",
    "database.insert(3, 'y_pred', y_pred)\n",
    "\n",
    "# compute the accuracy of the predictions on the database.\n",
    "measure_accuracy(database['categorical_label'], database['y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got 76% accuracy on whole database but it should be noted that this database is a super set of training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the features\n",
    "feature_file_path = '../dataset/features.csv'\n",
    "database.to_csv(feature_file_path,sep='       ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
